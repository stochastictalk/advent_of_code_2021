{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c93fcfa6-b9fa-41ed-a5d7-cbba8e134f23",
   "metadata": {},
   "source": [
    "# 🎅🤶 Advent of Code 2021 🌟☃️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f6e724-5c46-4301-afbb-78021e5a210d",
   "metadata": {},
   "source": [
    "https://adventofcode.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492922c7-8048-4df4-b681-ccbd922b2cbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44e0ba30-6cad-4919-8db5-d198cf133b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_data():\n",
    "    return pd.read_csv(os.path.join(\".\", \"data\", \"1.csv\"), header=None).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56813adc-d7aa-4d24-bf09-b3d58251e8c0",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ef900ce-64f2-4e21-86d8-84201873a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_times_increased():\n",
    "    return (load_data().diff().dropna() > 0.).aggregate(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0603db00-1b09-4607-9cad-370b28f1f5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1527"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_times_increased()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d500e074-b6b9-4ffa-a3a2-2dbfd18d712a",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74d6ce4f-f078-40f6-855e-1aea193a2503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_times_sum_increased():\n",
    "    return (load_data().rolling(3).sum().diff() > 0.).aggregate(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ced6b10-0cc6-4da9-a9da-3fd40aa6bf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1575"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_times_sum_increased()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121321e1-621e-4e31-b388-b6a742b37675",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6eae1dc4-b327-4b50-a289-76d1e7035b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(os.path.join(\".\", \"data\", \"2.csv\"), header=None)\n",
    "    df.columns = [\"raw\"]\n",
    "    df = df[\"raw\"].str.split(expand = True)\n",
    "    df.columns = [\"direction\", \"magnitude\"]\n",
    "    df[\"magnitude\"] = df[\"magnitude\"].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5ef54-ccc3-49ae-bd6a-9513a23d4d5b",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a7b3ba22-9da6-4265-8243-413dc61d9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_of_horizontal_and_vertical_location():\n",
    "    df = load_data()\n",
    "    agg_df = df.groupby(\"direction\").aggregate({\"magnitude\": sum})\n",
    "    return (agg_df.loc[\"down\", \"magnitude\"] - agg_df.loc[\"up\", \"magnitude\"])*agg_df.loc[\"forward\", \"magnitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "93a10e9d-16f0-4694-a71a-50af8ccd4de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1762050"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_product_of_horizontal_and_vertical_location()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b347cc15-abe3-489e-9baf-f37d3bdad301",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "147b022c-9338-43b6-b3a6-cff24455fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_of_horizontal_and_vertical_location():\n",
    "    df = load_data()\n",
    "    for direction in df[\"direction\"].unique():\n",
    "        df[direction] = (df[\"direction\"] == direction)*df[\"magnitude\"] # change in each direction at each time step\n",
    "    df[\"aim\"] = df[\"down\"].cumsum() - df[\"up\"].cumsum()\n",
    "    df[\"horizontal\"] = df[\"forward\"].cumsum()\n",
    "    df[\"depth\"] = (df[\"aim\"]*df[\"forward\"]).cumsum()\n",
    "    return (df[\"depth\"]*df[\"horizontal\"]).values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a208f1a3-97b1-45fb-89a1-a1a0ab273327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1855892637"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_product_of_horizontal_and_vertical_location()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e768f96-d079-4c90-a356-5b841355770d",
   "metadata": {},
   "source": [
    "# Day 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f8c206-8af6-4461-82c4-4a88bbaa26fb",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "20145089-6213-4e98-833b-4cfa380d0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_data():\n",
    "    with open(os.path.join(\".\", \"data\", \"3.csv\")) as file:\n",
    "        lines = file.readlines()\n",
    "    df = pd.DataFrame([list(l) for l in lines]).drop(12, axis=1) # drop newline column\n",
    "    return df\n",
    "    \n",
    "def get_power_consumption():\n",
    "    df = load_data()\n",
    "    gamma_rate = \"\".join(df.mode(axis=0).transpose().squeeze().values[:-1])\n",
    "    epsilon_rate = \"\".join([{\"0\":\"1\", \"1\": \"0\"}[c] for c in gamma_rate])\n",
    "    return int(gamma_rate, base=2)*int(epsilon_rate, base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "611ea1f1-fcf9-4701-908e-183b67f54e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325902"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_power_consumption()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652a655-915e-4d1a-b15a-473b71120b5b",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "83c9950b-2e9d-49c6-8e67-bfbb75c30194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_life_support_rating():\n",
    "    def _filter_by_bit_criterion(numbers_df, criterion, bit_i=0,):\n",
    "        if criterion == \"O2\":\n",
    "            numbers_df = numbers_df.loc[numbers_df[bit_i] == max(numbers_df[bit_i].mode()), :]\n",
    "        elif criterion == \"CO2\":\n",
    "            numbers_df = numbers_df.loc[numbers_df[bit_i] != max(numbers_df[bit_i].mode()), :]\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        \n",
    "        if numbers_df.shape[0] == 1:\n",
    "            return int(\"\".join(numbers_df.iloc[0, :].transpose().squeeze().values), base=2)\n",
    "        \n",
    "        else:\n",
    "            return _filter_by_bit_criterion(numbers_df, criterion, bit_i + 1)\n",
    "\n",
    "    co2_scrubber_rating = _filter_by_bit_criterion(load_data(), criterion = \"CO2\")\n",
    "    oxygen_generator_rating = _filter_by_bit_criterion(load_data(), criterion = \"O2\")\n",
    "    return co2_scrubber_rating*oxygen_generator_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0109618c-7cb0-46df-a34f-80b34f8e3df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482500"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_life_support_rating()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cabb21-65f7-4063-8b8a-ced4177950f2",
   "metadata": {},
   "source": [
    "# Day 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd36e5-a083-4b9c-bfb4-6c30fdb644da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to identify winning board, and the score of that board.\n",
    "# The winning board is the board which first marks a row or column from the list of numbers.\n",
    "# The score of the winning board is the sum of all of its unmarked numbers, multiplied by the\n",
    "# last number that was read out. \n",
    "\n",
    "# Initialise a set of boards.\n",
    "# Receive the first number.\n",
    "# Update the board base on the number, check if any of the boards have won.\n",
    "# If none of the boards have won, read the second number and repeat 3.\n",
    "# If a board has won, compute the winning score and identify the winning board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "416ae943-b1a7-4039-957e-014d7d83ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "class BingoBoard():\n",
    "    \n",
    "    def __init__(self, raw_board: list):\n",
    "        # raw_board is a length-n list of str,\n",
    "        # where each str contains n space-separated integers.\n",
    "        self.values = np.array([line.split() for line in raw_board], dtype = int)\n",
    "        self.marks = np.zeros(self.values.shape, dtype = bool)\n",
    "        self.n = self.values.shape[0]\n",
    "        self.in_play = True\n",
    "    \n",
    "    def update(self, number: int):\n",
    "        if self.in_play:\n",
    "            self.marks[(self.values == number)] = True\n",
    "        \n",
    "    def check_for_win(self, number: int):\n",
    "        if self.in_play and (np.any(self.marks.sum(axis = 0) == self.n) or\n",
    "                             np.any((self.marks.sum(axis = 1) == self.n))):\n",
    "            self.in_play = False\n",
    "            return np.sum(self.values[~self.marks])*number\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "def read_bingo_game(filepath: str):\n",
    "    with open(filepath) as file:\n",
    "        lines = file.readlines()\n",
    "    boards = []\n",
    "    current_board = []\n",
    "    for j, line in enumerate(lines):\n",
    "        if j == 0: # read list of called-out numbers\n",
    "            called_values = np.array(line.strip().split(\",\"), dtype = int)\n",
    "        \n",
    "        if j > 1: # read boards\n",
    "            if (re.search(\"[0-9]+\", line) is not None):\n",
    "                current_board.append(line.strip())\n",
    "            else:\n",
    "                boards.append(BingoBoard(current_board))\n",
    "                current_board = []\n",
    "            \n",
    "    return called_values, boards\n",
    "\n",
    "def evaluate_bingo_game(called_values: list, boards: list):\n",
    "    # called values is a list of integers.\n",
    "    # boards is a list of BingoBoards.\n",
    "    outcomes = [] # list of win indicators/board final scores\n",
    "    # round of play increases going down the rows,\n",
    "    # columns correspond to boards.\n",
    "    for called_value in called_values:\n",
    "        for board in boards:\n",
    "            board.update(called_value)\n",
    "        outcomes.append([board.check_for_win(called_value) for board in boards])\n",
    "    return np.array(outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3887ba3-d5a1-4a8f-8d55-70cbf142a61c",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "84ccccab-1975-42b5-8ee3-1ca87dde35ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First win\n",
    "def get_first_win():\n",
    "    called_values, boards = read_bingo_game(os.path.join(\".\", \"data\", \"4.csv\"))\n",
    "    outcomes = evaluate_bingo_game(called_values, boards)\n",
    "    n_rounds = outcomes.shape[0]\n",
    "    for j in range(n_rounds):\n",
    "        max_outcome = max(outcomes[j, :])\n",
    "        if max_outcome > 0:\n",
    "            return max_outcome\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b12ba2f7-d05b-499b-a6ef-ff7cbd8c4d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49686"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_first_win()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1397f50c-e92d-4e65-93be-e173576c6f2b",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a065dbea-149f-4776-8a44-03b81c07487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last win\n",
    "def get_last_win():\n",
    "    called_values, boards = read_bingo_game(os.path.join(\".\", \"data\", \"4.csv\"))\n",
    "    outcomes = evaluate_bingo_game(called_values, boards)\n",
    "    n_rounds = outcomes.shape[0]\n",
    "    for j in range(outcomes.shape[0]):\n",
    "        max_outcome = max(outcomes[n_rounds - 1 - j, :])\n",
    "        if max_outcome > 0:\n",
    "            return max_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fdf6a49a-3cd5-406d-a865-aa5bc65eec71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26878"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_last_win()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b530ead4-3fd1-45a4-af59-c42f69c4c4ba",
   "metadata": {},
   "source": [
    "# Day 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9239bb-7e67-4d90-8a11-862805f34cf1",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9ed79773-7b93-4183-baf1-7e588eecbfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b21b83c0-56af-4832-a30e-5ff4a3dc2d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-10\n",
    "\n",
    "def transform_vent_coords_to_points(vent_coords: str, ignore_diagonals = True):\n",
    "    origin, terminus = [\n",
    "        np.array(coords.split(\",\"), dtype = int)\n",
    "            for coords in re.findall(r\"[0-9,]+\", vent_coords)\n",
    "    ]\n",
    "    magnitude = np.sqrt(np.sum((terminus - origin)**2.))\n",
    "    direction = np.expand_dims((terminus - origin)/magnitude, axis = -1)\n",
    "    if np.all(np.abs(direction) > 0.7): # diagonal line\n",
    "        if ignore_diagonals:\n",
    "            return None\n",
    "        points = np.expand_dims(origin, axis = -1) + direction*np.arange(0., magnitude + EPS, np.sqrt(2))\n",
    "    else: # horizontal or vertical line\n",
    "        points = np.expand_dims(origin, axis = -1) + direction*np.arange(0., magnitude + EPS, 1.)\n",
    "    return np.rint(points).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d30609e0-30d7-4f35-96a9-441966dcfdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_vent_coords_collection(ignore_diagonals = True):\n",
    "    with open(os.path.join(\".\", \"data\", \"5.csv\")) as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    vent_points = [transform_vent_coords_to_points(vc, ignore_diagonals) for vc in lines]\n",
    "    vent_points = np.concatenate([vp for vp in vent_points if vp is not None])\n",
    "    \n",
    "    # Concatenate all vent points\n",
    "    return pd.Series([tuple(vent_point) for vent_point in vent_points]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "f9eb713b-495c-4476-9ec0-1f1e9f6168d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5169"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(analyse_vent_coords_collection(ignore_diagonals = True) >= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "768c4008-638b-4cfd-a527-c0367eac6a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22083"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(analyse_vent_coords_collection(ignore_diagonals = False) >= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd1eba-2288-4070-ace9-863a3df64648",
   "metadata": {},
   "source": [
    "# Day 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "8af4a7d2-7893-4ae9-ad62-25089adbc93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each lanternfish creates a new lanternfish once every 7 days.\n",
    "# After being born, a lanternfish has a timer value of 8.\n",
    "# After giving birth, a lanternfish has a timer value of 6.\n",
    "# The lanternfish gives birth in the interval between timer values of 0 and 6.\n",
    "\n",
    "# How many lanternfish would there be after 80 days?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d1273-52f7-4b94-840a-f7419a5cb34b",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "14e4964c-f0d8-4632-9b60-0e404254b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "a6cabe02-774e-489a-a1c6-fe581a51f65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lanternfish_data():\n",
    "    with open(os.path.join(\".\", \"data\", \"6.csv\")) as file:\n",
    "        data = np.array(file.readlines()[0].strip().split(\",\"), dtype = int)\n",
    "    return data\n",
    "\n",
    "def increment_lanternfish_data(data, n_days = 1):\n",
    "    # data is a 1d np.array of integers.\n",
    "    giving_birth = (data == 0)\n",
    "    data[giving_birth] = 6\n",
    "    data[~giving_birth] = data[~giving_birth] - 1\n",
    "    data = np.concatenate([data, np.full(shape = giving_birth.sum(), fill_value = 8)])\n",
    "    if (n_days - 1) == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return increment_lanternfish_data(data, n_days - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "7f3586e5-4c21-44ce-b7b3-b9d2533b6ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362639"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(increment_lanternfish_data(load_lanternfish_data(), n_days = 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02c366-5f0a-4b3c-a6fb-b7e593303755",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c5595-e411-4170-b527-ecdbf604dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part of the question asks us to compute the number of lanternfish\n",
    "# after 256 days. Doing this using the existing code would require too much memory.\n",
    "# Instead, we can keep track of the count of the number of lanternfish with k\n",
    "# days until giving birth. This will mean that the memory footprint of the lanternfish\n",
    "# tracker does not increase in proportion to the number of days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "564d7fb5-adfd-43f4-8fe0-745da6b372fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lanternfish_data_v2():\n",
    "    with open(os.path.join(\".\", \"data\", \"6.csv\")) as file:\n",
    "        data = np.array(file.readlines()[0].strip().split(\",\"), dtype = int)\n",
    "    data = pd.Series(data).value_counts()\n",
    "    for j in set(range(0, 9)) - set(data.index.values):\n",
    "        data[j] = 0\n",
    "    return data\n",
    "    \n",
    "def increment_lanternfish_data_v2(data, n_days = 1):\n",
    "    n_gave_birth = data[0]\n",
    "    for j in range(0, 8):\n",
    "        data[j] = data[j + 1]\n",
    "    data[8] = n_gave_birth\n",
    "    data[6] += n_gave_birth\n",
    "    if (n_days - 1) == 0:\n",
    "        return data.sum()\n",
    "    else:\n",
    "        return increment_lanternfish_data_v2(data, n_days - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "a8f1ddd7-b1a8-4518-a7c2-3485026e5a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362639"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment_lanternfish_data_v2(load_lanternfish_data_v2(), n_days = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "8bf5eeca-6dcc-4f3a-bbc9-52b6a311aac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1639854996917"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment_lanternfish_data_v2(load_lanternfish_data_v2(), n_days = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7ea2f-8dbc-4995-8130-718889c596f1",
   "metadata": {},
   "source": [
    "# Day 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c18744e-9655-4e52-8160-d77df86408c3",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "f87e912d-bc25-4231-9b2d-5b15d4ddc9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given x1, x2, ..., xn,\n",
    "# minimize sum_i(|xi - a|)\n",
    "# w.r.t. a.\n",
    "# The solution to this problem is the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "27b81f6c-dcfa-42b5-92b7-1bb642130494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "2b99e017-854d-4152-876c-8401582b4e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crab_data():\n",
    "    with open(os.path.join(\".\", \"data\", \"7.csv\")) as file:\n",
    "        data = np.array(file.readlines()[0].split(\",\"), dtype=float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d213c9ef-fcb5-4a4c-a431-0c4d4eda9ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340056.0"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(load_crab_data() - np.median(load_crab_data())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cc778f-4f13-4db5-ad0f-374947e8c018",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "e5675fa9-34d2-4514-9034-312907878597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "cea3e013-49c6-40b9-9f23-2a9a5143a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given x1, x2, ..., xn\n",
    "# minimize sum_i(0.5*|xi - a|(|xi - a| + 1))\n",
    "# w.r.t. a\n",
    "\n",
    "def cost_function(a: float, data: np.array):\n",
    "    return np.sum(0.5*np.abs(data - a)*(np.abs(data - a) + 1))\n",
    "\n",
    "def optimize_crab_location():\n",
    "    data = load_crab_data()\n",
    "    a_star = 0.\n",
    "    min_cost = np.inf\n",
    "    for a_dash in np.arange(np.min(data), np.max(data) + 1.):\n",
    "        cost_dash = cost_function(a_dash, data)\n",
    "        if  cost_dash < min_cost:\n",
    "            min_cost = cost_dash\n",
    "            a_star = a_dash\n",
    "    return a_star, min_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "aabe5ff1-73a0-464e-86aa-b944e6eb3cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460.0, 96592275.0)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_crab_location()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62892213-411f-4f3a-a4e2-1810f9b20b46",
   "metadata": {},
   "source": [
    "# Day 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a7f3b-ae4b-4974-b87b-33f6b8113b39",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "1daeb788-bdae-4a90-b42e-db3bb03e9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each display has segments a-g and display a number 0-9.\n",
    "# You make a note of all ten unique signal patterns you see,\n",
    "# and then write down a single four digit output value.\n",
    "# Use the signal patterns to figure out which pattern\n",
    "# corresponds to which digit, then decode the four-digit output\n",
    "# value.\n",
    "# Initially focus on easy digits - 1, 4, 7, 8\n",
    "\n",
    "def load_segments_data():\n",
    "    with open(os.path.join(\".\", \"data\", \"8.csv\")) as file:\n",
    "        lines = file.readlines()\n",
    "    signal_patterns, output_values = list(zip(*[line.split(\"|\") for line in lines]))\n",
    "    signal_patterns = [pattern.strip().split() for pattern in signal_patterns]\n",
    "    output_values = [output_value.strip().split() for output_value in output_values]\n",
    "    return signal_patterns, output_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "70ae6d48-5b7b-49e4-825c-069c7fa2468c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In the output values, how many times do digits 1, 4, 7, or 8 appear?\n",
    "\n",
    "def count_1_4_7_8_in_output_values():\n",
    "    _, output_values = load_segments_data()\n",
    "    return sum([count_1_4_7_8_in_output_value(output_value) for output_value in output_values])\n",
    "        \n",
    "def count_1_4_7_8_in_output_value(output_value: list):\n",
    "    return sum([len(entry) in [2, 4, 3, 7] for entry in output_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "26e901b2-b993-41bd-9d43-158e049bdab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1_4_7_8_in_output_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a989aed3-6685-45b3-be65-537889127cb8",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "3c7df1f1-0f42-4680-bcce-0a8915fda54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brute force solution - try each possible mapping.\n",
    "from itertools import permutations\n",
    "\n",
    "digit_to_segments = {\n",
    "    0: [\"A\", \"B\", \"C\", \"E\", \"F\", \"G\"],\n",
    "    1: [\"C\", \"F\"],\n",
    "    2: [\"A\", \"C\", \"D\", \"E\", \"G\"],\n",
    "    3: [\"A\", \"C\", \"D\", \"F\", \"G\"],\n",
    "    4: [\"B\", \"C\", \"D\", \"F\"],\n",
    "    5: [\"A\", \"B\", \"D\", \"F\", \"G\"],\n",
    "    6: [\"A\", \"B\", \"D\", \"E\", \"F\", \"G\"],\n",
    "    7: [\"A\", \"C\", \"F\"],\n",
    "    8: [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"],\n",
    "    9: [\"A\", \"B\", \"C\", \"D\", \"F\", \"G\"]\n",
    "}\n",
    "segments_to_digit = {\n",
    "    \"\".join(v): str(k) for k, v in digit_to_segments.items()\n",
    "}\n",
    "\n",
    "def decode_wire_to_segment_mapping(signal_pattern: list):\n",
    "    # There is a smarter way to do this but this way is easier to implement.\n",
    "    wires = [wire for wire in \"abcdefg\"]\n",
    "    valid_segment_illuminations = [\n",
    "        illuminated_segments for illuminated_segments in digit_to_segments.values()\n",
    "    ]\n",
    "    # Search over all possible wire-to-segment mappings.\n",
    "    for segment_order in permutations([segment for segment in \"ABCDEFG\"]):\n",
    "        M = {wire: segment for wire, segment in zip(wires, segment_order)}\n",
    "        valid_mapping = True\n",
    "        \n",
    "        for digit_str in signal_pattern:\n",
    "            illuminated_segments = sorted([M[wire] for wire in digit_str])\n",
    "            \n",
    "            # If mapping generates nonsensical illumination, move on\n",
    "            # to next candidate mapping M.\n",
    "            if illuminated_segments not in valid_segment_illuminations:\n",
    "                valid_mapping = False\n",
    "                break\n",
    "        \n",
    "        if valid_mapping:\n",
    "            return M\n",
    "            # If not, move on to next digit str\n",
    "            \n",
    "def decode_output_value_from_signal_pattern(signal_pattern: list, output_value: list):\n",
    "    wire_to_segment = decode_wire_to_segment_mapping(signal_pattern)\n",
    "    \n",
    "    def _map_output_value_to_digits(output_value: list, wire_to_segment: dict):\n",
    "        digits = []\n",
    "        for digit_str in output_value:\n",
    "            segments = \"\".join(sorted([wire_to_segment[wire] for wire in digit_str]))\n",
    "            digits.append(segments_to_digit[segments])\n",
    "        \n",
    "        return int(\"\".join(digits))\n",
    "    \n",
    "    return _map_output_value_to_digits(output_value, wire_to_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "997fcef7-8b34-469b-9155-09d02e8b2b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1084606"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_patterns, output_values = load_segments_data()\n",
    "\n",
    "sum([decode_output_value_from_signal_pattern(signal_pattern, output_value)\n",
    "        for signal_pattern, output_value in zip(signal_patterns, output_values)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f8ba5-e16c-4463-a84c-33d03b545370",
   "metadata": {},
   "source": [
    "# Day 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b8ba8-296c-49ee-933d-a9b0b0b93bd8",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b397c3-279d-4573-9f0a-5dde0c6259b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2199943210\n",
    "# 3987894921\n",
    "# 9856789892\n",
    "# 8767896789\n",
    "# 9899965678\n",
    "\n",
    "# Numbers are heights.\n",
    "# Find all the low points,\n",
    "# where a low point is a point with a value smaller\n",
    "# then its (up to) four adjacent points.\n",
    "# The risk level of a low point is 1 + its height.\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_height_data():\n",
    "    with open(os.path.join(\".\", \"data\", \"9.csv\")) as file:\n",
    "        lines = file.readlines()\n",
    "    return np.array([[int(h) for h in line.strip()] for line in lines])\n",
    "\n",
    "def identify_low_points(height_data: np.array):\n",
    "    # Could vectorize this.\n",
    "    low_points_grid = np.full(height_data.shape, fill_value = False)\n",
    "    height_data = np.pad(height_data, pad_width = 1, constant_values = 10) \n",
    "    for row_i in range(low_points_grid.shape[0]):\n",
    "        for col_i in range(low_points_grid.shape[1]):\n",
    "            low_points_grid[row_i, col_i] = np.all([\n",
    "                (height_data[row_i + 1, col_i + 1] - \\\n",
    "                    height_data[row_i + 1 + off_r, col_i + 1 + off_c]) < 0\n",
    "                for off_r, off_c in [(-1, 0), (1, 0), (0, 1), (0, -1)]\n",
    "            ])\n",
    "    \n",
    "    return low_points_grid\n",
    "\n",
    "def compute_risk_of_height_data(height_data: np.array):\n",
    "    low_points = identify_low_points(height_data)\n",
    "    return np.sum(height_data[low_points] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d9d178-e6a9-4923-a8e0-bb97d4319f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array([[int(h) for h in line] for line in \"\"\"2199943210\n",
    "3987894921\n",
    "9856789892\n",
    "8767896789\n",
    "9899965678\"\"\".split(\"\\n\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9912a4a-8857-44e9-9de3-19e562a4d8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_risk_of_height_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ec4114-df08-4529-97a1-9391ea2ae1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_risk_of_height_data(load_height_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248953ef-f6fd-4c37-805b-d2a414dc1c4e",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f9df278-36a8-4110-b519-2846aa7f5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dd441578-9d23-48f7-ad11-d7b40ca1c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_of_three_largest_basin_sizes(height_data: np.array):\n",
    "    # An edge (a, b) exists if a and b are adjacent and neither of them are equal to 9.\n",
    "    # Iterate over nodes, testing edges to below and to the right.\n",
    "    edges = []\n",
    "    for row_i in range(height_data.shape[0] - 1):\n",
    "        for col_i in range(height_data.shape[1] - 1):\n",
    "            for off_r, off_c in [(0, 1), (1, 0)]:\n",
    "                if height_data[row_i, col_i] != 9 and height_data[row_i + off_r, col_i + off_c] != 9:\n",
    "                    edges.append([(row_i, col_i), (row_i + off_r, col_i + off_c)])\n",
    "                    \n",
    "    # With this list of edges, create sets of nodes in each\n",
    "    # basin. A basin is a set of nodes.\n",
    "    # Iterate over edges. Take edge (a, b).\n",
    "    # Let Sa be the basin containing a, or {a} if this basin does not exist.\n",
    "    # Let Sb be the basin containing b, or {b} if this basin does not exist.\n",
    "    # Take the union of Sa and Sb.\n",
    "    basins = [{node} for node in list(set(node for edge in edges for node in edge))]\n",
    "    for node_a, node_b in edges:\n",
    "        # Get basin indices\n",
    "        Sa_i = np.argwhere([node_a in basin for basin in basins]).squeeze()\n",
    "        Sb_i = np.argwhere([node_b in basin for basin in basins]).squeeze()\n",
    "        \n",
    "        # Connect basins by merging them\n",
    "        basins[Sa_i] = basins[Sa_i].union(basins[Sb_i])\n",
    "        if Sa_i != Sb_i:\n",
    "            basins.pop(Sb_i)\n",
    "    \n",
    "    basin_sizes = sorted([len(basin) for basin in basins])\n",
    "    \n",
    "    return np.prod(basin_sizes[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "674ed122-9d3f-4317-968d-9eea7630b50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1045660"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_product_of_three_largest_basin_sizes(load_height_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c2cabd-4aca-484d-aed9-0f2514fd849d",
   "metadata": {},
   "source": [
    "# Day 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8427a4-b659-4d5a-9a93-270b773c579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrupted line = Line that has an equal number of opening and closing braces,\n",
    "# but these braces do not match.\n",
    "# Incomplete line = Line that does not have an equal number of opening and closing braces.\n",
    "\n",
    "# Find the first illegal character in each corrupted line of the navigation subsystem. What is the total syntax error score for those errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6fd8becb-dd48-4192-ad18-0129b1565c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8fd8f0d0-a251-45ed-b709-31491929c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_syntax_error_data():\n",
    "    with open(os.path.join(\".\", \"data\", \"10.csv\")) as file:\n",
    "        lines = [line.strip() for line in file.readlines()]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ae4fd-9603-41fa-b585-486555059650",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ce36b1f0-9439-4e0d-8157-415ccf6ffbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over characters of line.\n",
    "# If opening bracket, push to end of list of open brackets.\n",
    "# If closing bracket, check it matches the final entry in the list of open brackets.\n",
    "#    If it does not, raise a syntax error.\n",
    "#    If it does, pop the final entry in the list of open brackets.\n",
    "\n",
    "def find_first_syntax_error(line: str):\n",
    "    # Returns None if no syntax errors raised,\n",
    "    # illegal character otherwise.\n",
    "    close_to_open = {\n",
    "        \"]\": \"[\",\n",
    "        \")\": \"(\",\n",
    "        \"}\": \"{\",\n",
    "        \">\": \"<\"\n",
    "    }\n",
    "    open_brackets = \"\"\n",
    "    for c in line:\n",
    "        if c in \"([{<\":\n",
    "            open_brackets += c\n",
    "        elif c in \")]}>\":\n",
    "            if close_to_open[c] == open_brackets[-1]: # Correctly closes a chunk.\n",
    "                open_brackets = open_brackets[:-1]\n",
    "            else: # Does not correctly close a chunk.\n",
    "                return c\n",
    "            \n",
    "def compute_total_syntax_error_score():\n",
    "    char_to_points = {\n",
    "        \")\": 3,\n",
    "        \"]\": 57,\n",
    "        \"}\": 1197,\n",
    "        \">\": 25137\n",
    "    }\n",
    "    illegal_chars = [find_first_syntax_error(line) for line in load_syntax_error_data()]\n",
    "    return sum([char_to_points[c] for c in illegal_chars if c is not None])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a1eda51e-7e37-4505-8c33-dbf865557d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'}'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_line = \"{([(<{}[<>[]}>{[]{[(<()>\"\n",
    "check_syntax(test_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c623880d-76fa-43e0-bf4e-2fe5ae8e18c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319329"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_total_syntax_error_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44948e7-e8b6-44d3-9681-44eca17710a0",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b5266817-4a29-4ce9-9e51-d63ed19968a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_line(line: str):\n",
    "    close_to_open = {\n",
    "        \"]\": \"[\",\n",
    "        \")\": \"(\",\n",
    "        \"}\": \"{\",\n",
    "        \">\": \"<\"\n",
    "    }\n",
    "    open_to_close = {v: k for k, v in close_to_open.items()}\n",
    "    open_brackets = []\n",
    "    for c in line:\n",
    "        if c in \"([{<\":\n",
    "            open_brackets += c\n",
    "        elif c in \")]}>\":\n",
    "            if close_to_open[c] == open_brackets[-1]: # Correctly closes a chunk.\n",
    "                open_brackets = open_brackets[:-1]\n",
    "    \n",
    "    # Reverse remaining open brackets, map to closing brackets\n",
    "    return \"\".join([open_to_close[c] for c in open_brackets[::-1]])\n",
    "\n",
    "def score_autocompletion(line: str):\n",
    "    # line is a sequence of closing brackets\n",
    "    # Start with a total score of 0.\n",
    "    # Then, for each character, multiply the total score by 5 and then increase the total\n",
    "    # score by the point value given for the character in the following table:\n",
    "    char_to_points = {\n",
    "        \")\": 1,\n",
    "        \"]\": 2,\n",
    "        \"}\": 3,\n",
    "        \">\": 4\n",
    "    }\n",
    "    total_score = 0\n",
    "    for c in line:\n",
    "        total_score = total_score*5 + char_to_points[c]\n",
    "    return total_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "215c6f11-87b1-4f32-908e-fb0ba53475d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'}}]])})]'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_line = \"[({(<(())[]>[[{[]{<()<>>\" # - Complete by adding }}]])})].\n",
    "complete_line(test_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "efeb9c92-1c16-4cea-a02a-19bff11b9a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_autocompletion(\"])}>\") # 294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c17b94a8-6a88-48fd-bef5-0b3d53411219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard corrupted lines\n",
    "def compute_middle_autocomplete_score():\n",
    "    incomplete_lines = [line for line in load_syntax_error_data() if find_first_syntax_error(line) is None]\n",
    "    autocompletions = [complete_line(line) for line in incomplete_lines]\n",
    "    return np.median([score_autocompletion(ac) for ac in autocompletions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "47d381e7-0527-4a3d-ab7f-84864073bd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3515583998.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_middle_autocomplete_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be4d3a-9f5c-45ba-8fa6-4a14b994c859",
   "metadata": {},
   "source": [
    "# Day 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac457e10-641a-449f-85d9-189afcea85ba",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc8dbf-455c-4028-b102-40fba0536a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the energy level of each octopus increases by 1\n",
    "# Then, any octopus with an energy level greater than 9 flashes.\n",
    "# This increases the energy level of all adjacent octopuses by 1, including\n",
    "# octopuses that are diagonally adjacent. If this causes an octopus to have\n",
    "# an energy level greater than 9, it also flashes. This process continues as \n",
    "# long as new octopuses keep having their energy level increased beyond 9.\n",
    "# (An octopus can only flash at most once per step.)\n",
    "# Finally, any octopus that flashed during this step has its energy level set\n",
    "# to 0, as it used all of its energy to flash.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c661ad5d-bd76-4435-a64d-a9308e1dcb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_octopus_data(test = False):\n",
    "    if test:\n",
    "        lines = \"\"\"5483143223\n",
    "                    2745854711\n",
    "                    5264556173\n",
    "                    6141336146\n",
    "                    6357385478\n",
    "                    4167524645\n",
    "                    2176841721\n",
    "                    6882881134\n",
    "                    4846848554\n",
    "                    5283751526\"\"\".split(\"\\n\")\n",
    "    else:\n",
    "        with open(os.path.join(\".\", \"data\", \"11.csv\")) as file:\n",
    "            lines = file.readlines()\n",
    "    return np.array([[int(c) for c in line.strip()] for line in lines])\n",
    "\n",
    "def iterate_octopus_data(energy_levels: np.array, n_iter = 1):\n",
    "    energy_levels = energy_levels + 1\n",
    "    \n",
    "    def _propagate_flash(energy_levels: np.array):        \n",
    "        if np.sum(energy_levels > 9) == 0:\n",
    "            return energy_levels\n",
    "        else:\n",
    "            flashing_octopi = (energy_levels > 9)\n",
    "            energy_levels[flashing_octopi] = 0\n",
    "            flashing_octopi_padded = np.pad(flashing_octopi, pad_width = 1, constant_values = False)\n",
    "            for row_i, col_i in np.argwhere(energy_levels > 0): \n",
    "                energy_levels[row_i, col_i] += np.sum(flashing_octopi_padded[row_i:(row_i + 3), col_i:(col_i + 3)])\n",
    "            \n",
    "            return _propagate_flash(energy_levels)\n",
    "    \n",
    "    energy_levels = _propagate_flash(energy_levels)\n",
    "    if n_iter == 1:\n",
    "        return energy_levels\n",
    "    else:\n",
    "        return iterate_octopus_data(energy_levels, n_iter = n_iter - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7a3a40df-246c-4a39-8ee6-1d2916970b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_flashes(n_iter = 100, test = False):\n",
    "    total_flashes = 0\n",
    "    energy_levels = load_octopus_data(test)\n",
    "    for j in range(n_iter):\n",
    "        energy_levels = iterate_octopus_data(energy_levels)\n",
    "        total_flashes += np.sum(energy_levels == 0)\n",
    "    \n",
    "    return total_flashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "dbef5fce-1b40-455c-a366-baf72bea24e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1656"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_total_flashes(test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7a771cde-437f-40a3-8d24-d83061885f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1642"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_total_flashes(test = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27a2a47-4cee-4bc4-b25b-51c15328fa0d",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ae8e9e70-b172-4600-90a8-e83be799333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_first_step_of_simultaneous_flash(test = False):\n",
    "    energy_levels = load_octopus_data(test)\n",
    "    n_octopi = energy_levels.shape[0]*energy_levels.shape[1]\n",
    "    step = 0\n",
    "    while True:\n",
    "        if np.sum(energy_levels == 0) == n_octopi:\n",
    "            return step\n",
    "        else:\n",
    "            energy_levels = iterate_octopus_data(energy_levels)\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0008c633-f734-4e74-99a4-b29f5db10e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_first_step_of_simultaneous_flash(test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "67b9d6c3-c1b5-4696-b025-dfb13dd97189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_first_step_of_simultaneous_flash(test = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26315c3e-7806-44c7-ba7d-6820621fc4ec",
   "metadata": {},
   "source": [
    "# Day 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38672ef6-cf72-4d14-8873-48fcbb039acf",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b6bbbcba-8b11-49e5-9f7e-aeea82bdeae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [1, 2, 3]\n",
    "my_list.remove(2)\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c8bfe31d-b9e7-4fed-96d9-ad04217a0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_paths_data(test = False):\n",
    "    if test:\n",
    "        lines = \"\"\"dc-end\n",
    "                    HN-start\n",
    "                    start-kj\n",
    "                    dc-start\n",
    "                    dc-HN\n",
    "                    LN-dc\n",
    "                    HN-end\n",
    "                    kj-sa\n",
    "                    kj-HN\n",
    "                    kj-dc\"\"\".split(\"\\n\")\n",
    "    else:\n",
    "        with open(os.path.join(\".\", \"data\", \"12.csv\")) as file:\n",
    "            lines = file.readlines()\n",
    "    edges = [line.strip().split(\"-\") for line in lines]\n",
    "    nodes = list(set(node for edge in edges for node in edge))\n",
    "    \n",
    "    def _get_connected_nodes(src_node, edges):\n",
    "        connected_nodes = list(set(node for edge in edges for node in edge if src_node in edge))\n",
    "        connected_nodes.remove(src_node)\n",
    "        return connected_nodes\n",
    "    \n",
    "    return {node: _get_connected_nodes(node, edges) for node in nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "bf62f86a-5b75-4df8-806c-f196569e02b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a tree with a root at \"start\" and leaves at \"end\".\n",
    "\n",
    "# Say we have a start node.\n",
    "# Generate each possible path from that start node.\n",
    "# For each generated path that does not terminate in \"end\",\n",
    "# generate each possible path to another node.\n",
    "# Terminate when no paths do not terminate in \"end\".\n",
    "\n",
    "\n",
    "def extend_paths(connected_nodes: dict, paths=[[\"start\"]]):\n",
    "    updated_paths = []\n",
    "    for path in paths:\n",
    "        if path[-1] != \"end\": # Path needs extending\n",
    "            lowercase_nodes_of_path = [n for n in path if n.islower()]\n",
    "            has_visited_lowercase_node_twice = np.any(np.unique(lowercase_nodes_of_path, return_counts = True)[1] == 2)\n",
    "            # has_visited_lowercase_node_twice = True # for part 1 soln\n",
    "            for node in connected_nodes[path[-1]]:\n",
    "                if node == \"start\":\n",
    "                    pass\n",
    "                elif has_visited_lowercase_node_twice:\n",
    "                    if (node not in lowercase_nodes_of_path):\n",
    "                        updated_paths.append(path + [node])\n",
    "                        # NB path is dropped if no movement is possible\n",
    "                else:\n",
    "                    updated_paths.append(path + [node])\n",
    "                \n",
    "        else: # Path is already complete\n",
    "            updated_paths.append(path)\n",
    "    \n",
    "    return updated_paths\n",
    "\n",
    "def find_paths(connected_nodes: dict):\n",
    "    paths = [[\"start\"]]\n",
    "    extended_paths = extend_paths(connected_nodes, paths)\n",
    "    while extended_paths != paths:\n",
    "        paths = extended_paths\n",
    "        extended_paths = extend_paths(connected_nodes, paths)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "376c8c98-d063-4819-ac98-4e73b6d1663a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['start', 'dc'], ['start', 'HN'], ['start', 'kj']]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extend_paths(load_paths_data(test = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1a31ec54-6436-47b6-be85-5d71512ccfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(find_paths(load_paths_data(test = True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "adc42590-4490-49c8-8568-33207aa6d638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150004"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(find_paths(load_paths_data(test = False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75d347-edbc-42b8-8425-a93211dbd744",
   "metadata": {},
   "source": [
    "# Day 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "689e8a56-f523-4b6b-8864-ecd1ffa5a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def load_folds_data(test = False):\n",
    "    if not test:\n",
    "        with open(os.path.join(\".\", \"data\", \"13.csv\")) as file:\n",
    "            lines = file.readlines()\n",
    "    else:\n",
    "        lines = \"\"\"\n",
    "            6,10\n",
    "            0,14\n",
    "            9,10\n",
    "            0,3\n",
    "            10,4\n",
    "            4,11\n",
    "            6,0\n",
    "            6,12\n",
    "            4,1\n",
    "            0,13\n",
    "            10,12\n",
    "            3,4\n",
    "            3,0\n",
    "            8,4\n",
    "            1,10\n",
    "            2,14\n",
    "            8,10\n",
    "            9,0\n",
    "\n",
    "            fold along y=7\n",
    "            fold along x=5\n",
    "        \"\"\".split(\"\\n\")\n",
    "    \n",
    "    lines = [line for line in lines if len(line.strip()) > 0] # Remove empty lines\n",
    "    mark_coords = np.array([line.strip().split(\",\") for line in lines if \"fold\" not in line]).astype(int)\n",
    "    fold_instructions = [re.search(\"([xy])=([0-9]+)\", line.strip()).group(1, 2) for line in lines if \",\" not in line]\n",
    "    fold_instructions = [[axis, int(location)] for axis, location in fold_instructions]\n",
    "    return mark_coords, fold_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "9826f97f-da2d-4491-ab03-ebc700c28019",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fold(mark_coords: np.array, fold_instruction):\n",
    "    fold_axis, fold_location = fold_instruction\n",
    "    j = {\"x\": 0, \"y\": 1}[fold_axis]\n",
    "    width = max(mark_coords[:, j])\n",
    "    beyond_fold = (mark_coords[:, j] > fold_location)\n",
    "    before_fold = (mark_coords[:, j] < fold_location)\n",
    "    if fold_location >= width/2:\n",
    "        offset = width - 2*(width - fold_location)\n",
    "        mark_coords[beyond_fold, j] = offset + (width - mark_coords[beyond_fold, j])\n",
    "    if fold_location < width/2:\n",
    "        mark_coords[beyond_fold, j] = (width - mark_coords[beyond_fold, j])\n",
    "        mark_coords[before_fold, j] = (width - fold_location*2) + mark_coords[before_fold, j]\n",
    "    return np.unique(mark_coords, axis = 0)\n",
    "\n",
    "def display_marks(mark_coords: np.array):\n",
    "    marks = np.full(np.max(mark_coords, axis=0)[::-1] + 1, fill_value = \".\")\n",
    "    for coord in mark_coords:\n",
    "        marks[coord[1], coord[0]] = \"#\"\n",
    "    return \"\\n\".join([\"\".join(row) for row in marks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "9180aaee-8df1-4b72-8091-05c99d2a5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_coords, fold_instructions = load_folds_data(test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "638a90f5-f619-4788-b5a2-3b139c335c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####\n",
      "#...#\n",
      "#...#\n",
      "#...#\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "print(display_marks(fold(fold(mark_coords, fold_instructions[0]), fold_instructions[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "5685ca71-3bfc-4229-9cb8-6e698a9d5207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_n_marks_visible_after_first_fold():\n",
    "    mark_coords, fold_instructions = load_folds_data()\n",
    "    mark_coords = fold(mark_coords, fold_instructions[0])\n",
    "    return mark_coords.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "870f2f64-29c0-4169-902e-1815d8ac691d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "837"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_n_marks_visible_after_first_fold()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be94fa94-a2a8-4130-8584-42beba53158f",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "c9c5f576-84e8-4081-92da-aa2c30cb3dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_all_fold_instructions():\n",
    "    mark_coords, fold_instructions = load_folds_data()\n",
    "    for fold_instruction in fold_instructions:\n",
    "        mark_coords = fold(mark_coords, fold_instruction)\n",
    "    return mark_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "b258b9a8-c7eb-4a71-a28f-974393b8d5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####.###..####..##..#..#..##..#..#.#..#\n",
      "#....#..#....#.#..#.#.#..#..#.#..#.#..#\n",
      "###..#..#...#..#....##...#....####.#..#\n",
      "#....###...#...#.##.#.#..#....#..#.#..#\n",
      "#....#....#....#..#.#.#..#..#.#..#.#..#\n",
      "####.#....####..###.#..#..##..#..#..##.\n"
     ]
    }
   ],
   "source": [
    "print(display_marks(execute_all_fold_instructions()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09160945-cce3-48d8-a976-6f6b2dfbfb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPZGKCHU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce85042-2185-4636-9e87-88dbe833ca51",
   "metadata": {},
   "source": [
    "# Day 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "840dcc08-b7d1-4358-9c32-6b45ea77e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def load_polymer_data(test = False):\n",
    "    if test:\n",
    "        lines = \"\"\"NNCB\n",
    "                CH -> B\n",
    "                HH -> N\n",
    "                CB -> H\n",
    "                NH -> C\n",
    "                HB -> C\n",
    "                HC -> B\n",
    "                HN -> C\n",
    "                NN -> C\n",
    "                BH -> H\n",
    "                NC -> B\n",
    "                NB -> B\n",
    "                BN -> B\n",
    "                BB -> N\n",
    "                BC -> B\n",
    "                CC -> N\n",
    "                CN -> C\n",
    "                \"\"\".split(\"\\n\")\n",
    "    else:\n",
    "        with open(os.path.join(\".\", \"data\", \"14.csv\")) as file:\n",
    "            lines = file.readlines()\n",
    "    \n",
    "    return lines[0].strip(), [re.match(\"([A-Z]{2}) -> ([A-Z]{1})\", line.strip()).group(1, 2)\n",
    "                              for line in lines[1:] if len(line.strip()) > 0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69326da9-a2a0-45db-813b-56415eebdb23",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "41b75872-92ca-4612-9867-ba502e287ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_instructions(polymer: str, instructions: list, n_steps = 1):\n",
    "    # Extract pairs, inserted_chars\n",
    "    pairs, insertions = list(zip(*instructions))\n",
    "    \n",
    "    # Iterate over characters of polymer\n",
    "    c0 = polymer[0]\n",
    "    new_polymer = polymer[0]\n",
    "    for j in range(1, len(polymer)):\n",
    "        c1 = polymer[j]\n",
    "        try: # Insert value if c0 + c1 is in pairs\n",
    "            new_polymer = new_polymer + insertions[pairs.index(c0 + c1)] + c1\n",
    "        except ValueError: # If c0 + c1 not in pairs\n",
    "            new_polymer = new_polymer + c1\n",
    "        c0 = c1\n",
    "        \n",
    "    if n_steps == 1:\n",
    "        return new_polymer\n",
    "    else:\n",
    "        return apply_instructions(new_polymer, instructions, n_steps = n_steps - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "2372c7b5-d344-428f-af79-d2c9745d062c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NBCCNBBBCBHCB'"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polymer, instructions = load_polymer_data(test = True)\n",
    "apply_instructions(polymer, instructions, n_steps = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "faa77638-365d-4d5b-86f1-ba5a705fb8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([c for c in \"aabbc\"], return_counts = True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "09550dee-cc2b-4003-9a99-64566cac0244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_most_common_char_minus_n_least_common_char(s: str):\n",
    "    char_counts = np.unique([c for c in s], return_counts = True)[1]\n",
    "    return max(char_counts) - min(char_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febdcee4-bf1e-4014-872e-9415999a477b",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "4c6971ca-c7aa-41f8-aab3-d3db568dafd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polymer_to_pair_counts(polymer: str):\n",
    "    pair_counts = {}\n",
    "    for j in range(1, len(polymer)):\n",
    "        pair = polymer[(j-1):(j+1)]\n",
    "        pair_counts[pair] = pair_counts.get(pair, 0) + 1\n",
    "    return pair_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "bcc526f1-e0b3-4269-b060-aa7b2a750196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_instructions_v2(pair_counts: dict, instructions: list, n_steps = 1):\n",
    "    # Iterate over pairs in pair_counts\n",
    "    # If pair in insertions, update pair_counts\n",
    "    pairs, insertions = list(zip(*instructions))\n",
    "    for pair, n in list(pair_counts.items()):\n",
    "        try: # In instructions\n",
    "            inserted_c = insertions[pairs.index(pair)]\n",
    "            pair_counts[pair[0] + inserted_c] = pair_counts.get(pair[0] + inserted_c, 0) + n\n",
    "            pair_counts[inserted_c + pair[1]] = pair_counts.get(inserted_c + pair[1], 0) + n\n",
    "            pair_counts[pair] = pair_counts[pair] - n\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    if n_steps == 1:\n",
    "        return pair_counts\n",
    "    else:\n",
    "        return apply_instructions_v2(pair_counts, instructions, n_steps = n_steps - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "a8af21b8-2bf9-45c1-9e2d-d59cb12b2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_counts_to_char_counts(pair_counts: dict, first_char, last_char):\n",
    "    char_counts = {}\n",
    "    for pair, count in pair_counts.items():\n",
    "        for c in pair:\n",
    "            char_counts[c] = char_counts.get(c, 0) + count\n",
    "            \n",
    "    char_counts[first_char] += 1\n",
    "    char_counts[last_char] += 1\n",
    "    char_counts = {k: v//2 for k, v in char_counts.items()}\n",
    "    return char_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "aee266c9-a577-4b28-873f-6ba011041f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_most_common_char_minus_n_least_common_char_v2(polymer: str, instructions: list, n_steps: int):\n",
    "    pair_counts = polymer_to_pair_counts(polymer)\n",
    "    pair_counts = apply_instructions_v2(pair_counts, instructions, n_steps)\n",
    "    char_counts = pair_counts_to_char_counts(pair_counts, polymer[0], polymer[1])\n",
    "    return max(char_counts.values()) - min(char_counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "f09dfc25-cffb-4329-984e-3bb1f9b86c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2265039461737"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polymer, instructions = load_polymer_data(test = False)\n",
    "n_most_common_char_minus_n_least_common_char_v2(polymer, instructions, n_steps = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c78494-6d53-4b85-9ba0-464a17e78bd9",
   "metadata": {},
   "source": [
    "# Day 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "id": "b1b65068-cbe5-45c5-9d92-233d28b3225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mollusc_data(test = False):\n",
    "    if test:\n",
    "        lines = \"\"\"\n",
    "            1163751742\n",
    "            1381373672\n",
    "            2136511328\n",
    "            3694931569\n",
    "            7463417111\n",
    "            1319128137\n",
    "            1359912421\n",
    "            3125421639\n",
    "            1293138521\n",
    "            2311944581\n",
    "        \"\"\".split(\"\\n\")\n",
    "    else:\n",
    "        with open(os.path.join(\".\", \"data\", \"15.csv\")) as file:\n",
    "            lines = file.readlines()\n",
    "    \n",
    "    return np.array([[c for c in line.strip()] for line in lines if len(line.strip()) > 0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "id": "4998bd10-499e-4e95-b023-a61c3ea526b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "def find_shortest_path(node_costs, start_node):\n",
    "    \"\"\" Implementation of a modified version of Dijkstra's algorithm for finding the shortest path\n",
    "        through a weighted graph.\n",
    "    \"\"\"\n",
    "    def _node_neighbours(node: tuple, node_costs: np.array, unvisited_nodes: set):\n",
    "        return [(neighbour, node_costs[neighbour[0], neighbour[1]])\n",
    "                for neighbour in [(node[0] - 1, node[1]), (node[0], node[1] - 1), (node[0], node[1] + 1), (node[0] + 1, node[1])]  \n",
    "                if neighbour in unvisited_nodes]\n",
    "                \n",
    "        return node_neighbours\n",
    "    \n",
    "    def _get_current_node(tentative_distances: dict, n_rows, n_cols):\n",
    "        # return min(tentative_distances, key = tentative_distances.get) # Dijkstra's algorithm\n",
    "        # tentative_distances contains upper bounds on the minimum distance to each unvisited node.\n",
    "        # below uses A* cost with an admissible heuristic function.\n",
    "        return min(tentative_distances, key = lambda k: tentative_distances[k] + (n_rows - 1 - k[0] + n_cols - 1 - k[1]))\n",
    "    \n",
    "    n_rows, n_cols = node_costs.shape\n",
    "    nodes = list(product(range(n_rows), range(n_cols)))\n",
    "    end_node = tuple(np.max(nodes, axis = 0).astype(int))\n",
    "    unvisited_nodes = set(nodes)\n",
    "    #tentative_distances = {node: 9*(node[0] + node[1]) for node in nodes}\n",
    "    tentative_distances = {}\n",
    "    tentative_distances[start_node] = 0\n",
    "    current_node = start_node\n",
    "    \n",
    "    while True:\n",
    "        # Iterate over neighbours of current node.\n",
    "        for neighbour, distance in _node_neighbours(current_node, node_costs, unvisited_nodes):\n",
    "            # The most promising node is the one with smallest minimum tentative distance to the end,\n",
    "            # not the smallest minimum tentative distance to the start.\n",
    "            distance_from_start_to_neighbour_via_current_node = tentative_distances[current_node] + distance\n",
    "            if distance_from_start_to_neighbour_via_current_node < tentative_distances.get(neighbour, np.inf):\n",
    "                tentative_distances[neighbour] = distance_from_start_to_neighbour_via_current_node\n",
    "        \n",
    "        # Break if the end node has been visited.\n",
    "        if current_node == end_node:\n",
    "            break\n",
    "            \n",
    "        # Mark the current node as visited.\n",
    "        unvisited_nodes.remove(current_node)\n",
    "        del tentative_distances[current_node]\n",
    "        \n",
    "        # Set current node to unvisited node with smallest tentative distance.\n",
    "        current_node = _get_current_node(tentative_distances, n_rows, n_cols)\n",
    "    \n",
    "    return tentative_distances[end_node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "id": "e4062ab9-3b8f-4095-a032-91a5df732e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 1074,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_shortest_path(load_mollusc_data(True), (0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "302edf4a-022c-4056-ad1f-972f17a9a535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562"
      ]
     },
     "execution_count": 1075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_shortest_path(load_mollusc_data(False), (0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff08d5-eee2-4a05-96e5-3f10a9b11d9b",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "id": "9537e23c-7449-4800-ae98-f0f64c495c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_node_costs(node_costs: np.array):\n",
    "    nrow, ncol = node_costs.shape\n",
    "    expanded_node_costs = np.zeros([nrow*5, ncol*5])\n",
    "    for row_i in range(5):\n",
    "        for col_i in range(5):\n",
    "            tile = node_costs + row_i + col_i\n",
    "            mask = tile > 9\n",
    "            tile[mask] = np.mod(tile[mask], 10) + 1\n",
    "            expanded_node_costs[(row_i*nrow):((row_i + 1)*nrow), (col_i*ncol):((col_i + 1)*ncol)] = tile\n",
    "    return expanded_node_costs.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "id": "059626c9-837b-4ee7-8b98-39115c9867d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 1079,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_shortest_path(expand_node_costs(load_mollusc_data(True)), start_node = (0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "id": "e140adb4-5914-4111-bc63-b3bc20f09ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2874"
      ]
     },
     "execution_count": 1080,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_shortest_path(expand_node_costs(load_mollusc_data(False)), start_node = (0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a749a65d-faee-4889-a642-39662c5727af",
   "metadata": {},
   "source": [
    "# Day 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ec6c1-18c5-4b4a-bcc3-8ab4f024c5e7",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "id": "de548d9c-a7ea-43e7-b03e-756b70caa154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_bits_data():\n",
    "    with open(os.path.join(\".\", \"data\", \"16.csv\")) as file:\n",
    "        lines = file.readlines()\n",
    "    data_hex = [line.strip() for line in lines if len(line) > 0][0]\n",
    "    \n",
    "    def _hex_to_bin(c: str):\n",
    "        return str(bin(int(c, 16)))[2:].zfill(4)\n",
    "\n",
    "    data_bin = \"\".join([_hex_to_bin(c) for c in data_hex])\n",
    "    return data_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "id": "f8713d94-82f3-4223-8c09-feb5d8d49813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_packet_version(data_bin: str):\n",
    "    return int(data_bin[0:3], 2), data_bin[3:]\n",
    "\n",
    "def get_packet_type_id(data_bin: str):\n",
    "    return get_packet_version(data_bin)\n",
    "\n",
    "def consume_binary_number_chunk(data_bin: str):\n",
    "    leading_bit = data_bin[0]\n",
    "    number_chunk = data_bin[1:5]\n",
    "    return leading_bit, number_chunk, data_bin[5:]\n",
    "\n",
    "def consume_literal(data_bin: str):\n",
    "    parsed_binary_number = \"\"\n",
    "    leading_bit = \"\"\n",
    "    while leading_bit != \"0\":\n",
    "        leading_bit, number_chunk, data_bin = consume_binary_number_chunk(data_bin)\n",
    "        parsed_binary_number += number_chunk\n",
    "    \n",
    "    return int(parsed_binary_number, 2), data_bin.rstrip(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "id": "43d4d0fb-739f-4688-acc5-00b12f1115f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_packet(data_bin: str):\n",
    "    packet = {}\n",
    "    packet[\"version\"], data_bin = get_packet_version(data_bin)\n",
    "    packet[\"type_id\"], data_bin = get_packet_type_id(data_bin)\n",
    "    if packet[\"type_id\"] == 4: # Literal packet\n",
    "        packet[\"value\"], data_bin = consume_literal(data_bin)\n",
    "    else: # Operator packet - contains other packets\n",
    "        packet_length_type_id = data_bin[0]\n",
    "        data_bin = data_bin[1:]\n",
    "        if packet_length_type_id == \"0\":\n",
    "            length_of_subpackets = int(data_bin[:15], 2) # in bits\n",
    "            data_bin = data_bin[15:]\n",
    "            init_data_bin_length = len(data_bin)\n",
    "            while ((init_data_bin_length - len(data_bin)) < length_of_subpackets) and len(data_bin) > 0:\n",
    "                child, data_bin = parse_packet(data_bin)\n",
    "                packet[\"children\"] = packet.get(\"children\", []) + [child]\n",
    "        else:\n",
    "            number_of_subpackets = int(data_bin[:11], 2)\n",
    "            data_bin = data_bin[11:]\n",
    "            while (len(packet.get(\"children\", [])) < number_of_subpackets) and len(data_bin) > 0:\n",
    "                child, data_bin = parse_packet(data_bin)\n",
    "                packet[\"children\"] = packet.get(\"children\", []) + [child]\n",
    "        \n",
    "    return packet, data_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "id": "c94173b3-729c-4993-9274-e8df24b5f8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'version': 7,\n",
       "  'type_id': 3,\n",
       "  'children': [{'version': 2, 'type_id': 4, 'value': 1},\n",
       "   {'version': 4, 'type_id': 4, 'value': 2},\n",
       "   {'version': 1, 'type_id': 4, 'value': 3}]},\n",
       " '')"
      ]
     },
     "execution_count": 1214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_packet(\"11101110000000001101010000001100100000100011000001100000\") # expect 7, 3, (1 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "id": "f47a0946-0523-45d4-8b2b-ff48496db844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': 6, 'type_id': 4, 'value': 2021}"
      ]
     },
     "execution_count": 1215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_packet(\"110100101111111000101000\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "id": "0694f200-e83d-49b4-8f66-4323dc3f5804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_version_number_to_total(packet: dict, version_total: int):\n",
    "    version_total += int(packet[\"version\"])\n",
    "    for child in packet.get(\"children\", []):\n",
    "        version_total = add_version_number_to_total(child, version_total)\n",
    "    \n",
    "    return version_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "id": "86597390-21a2-4203-b904-acff2fe64430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 1217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_version_number_to_total(parse_packet(\"11101110000000001101010000001100100000100011000001100000\")[0], 0) # expect 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "id": "51a02940-480e-4412-a37a-bae888e82ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "965"
      ]
     },
     "execution_count": 1218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_version_number_to_total(parse_packet(load_bits_data())[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9039fd-48b1-42b1-9fb1-3b2a54d32ac0",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "id": "2bee73fc-7f00-402c-aa72-7fd145110fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "id": "e086344b-feee-46fa-81bb-6f75779e5701",
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE_ID_TO_OPERATOR = {\n",
    "    0: sum,\n",
    "    1: prod,\n",
    "    2: min,\n",
    "    3: max,\n",
    "    5: lambda v: int(v[0] > v[1]),\n",
    "    6: lambda v: int(v[0] < v[1]),\n",
    "    7: lambda v: int(v[0] == v[1])\n",
    "}\n",
    "\n",
    "def evaluate_packet_value(packet: dict):\n",
    "    # Converts a packet from a parent node to a leaf node\n",
    "    # by evaluating the expression it contains.\n",
    "    if \"children\" in packet.keys():\n",
    "        return TYPE_ID_TO_OPERATOR[packet[\"type_id\"]]([evaluate_packet_value(child) for child in packet[\"children\"]])\n",
    "    else:\n",
    "        return packet[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "id": "ca8a3404-3278-4da1-90e4-9d8203a40db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_packet_value(parse_packet(\"11101110000000001101010000001100100000100011000001100000\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a39ce1-26d3-474f-8b2e-a900dec21976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
